---
title: "Desicion tree assignment"
author: "Anastasiia Tolstokorova"
date: "10 03 2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

This assignment is based on materials from [mlcourse.ai] (https://mlcourse.ai)

## Building a decision tree for predicting heart diseases

Let's read the data on heart diseases. The dataset can be downloaded from the course repo from [here](https://www.dropbox.com/s/kr1d9vsnax5wxfo/mlbootcamp5_train.csv?dl=0).

**Problem**

Predict presence or absence of cardiovascular disease (CVD) using the patient examination results.

**Data description**

There are 3 types of input features:

- *Objective*: factual information;
- *Examination*: results of medical examination;
- *Subjective*: information given by the patient.

| Feature | Variable Type | Variable      | Value Type |
|---------|--------------|---------------|------------|
| Age | Objective Feature | age | int (days) |
| Height | Objective Feature | height | int (cm) |
| Weight | Objective Feature | weight | float (kg) |
| Gender | Objective Feature | gender | categorical code |
| Systolic blood pressure | Examination Feature | ap_hi | int |
| Diastolic blood pressure | Examination Feature | ap_lo | int |
| Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |
| Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |
| Smoking | Subjective Feature | smoke | binary |
| Alcohol intake | Subjective Feature | alco | binary |
| Physical activity | Subjective Feature | active | binary |
| Presence or absence of cardiovascular disease | Target Variable | cardio | binary |

All of the dataset values were collected at the moment of medical examination.

## Task

Read the data
```{r}
# code for reading data
dt<-read.csv("./mlbootcamp5_train.csv",sep=";")
```

Transform the features: 
- create "age in years" (`age_years`)dividing age by 365.25 and taking floor ($\lfloor{x}\rfloor$ is the largest integer that is less than or equal to $x$)
- remove "age" feature
- transfrom `cholesterol` and `gluc` to factor

```{r}
# your code here
dt$age_years<-floor(dt$age/365.25)
dt<-subset(dt,select=c(cardio,gender,height,weight,ap_hi,ap_lo,cholesterol,gluc,smoke,alco,active,age_years))

dt$cholesterol<-as.factor(dt$cholesterol)
dt$gluc<-as.factor(dt$gluc)
dt$cardio<-as.factor(dt$cardio)
```

Split data into train and test parts in the proportion of 7/3.
The target feature is `cardio`

```{r}
# Your code here
library(caret)
set.seed(1953)
index<-createDataPartition(dt$cardio,p=0.7,list=FALSE,times=1)
training<-dt[index,]
test<-dt[-index,]
```

Train a decision tree on the dataset `training` with **max depth equal to 3**. For setting this parameter use function `rpart::rpart.control`. Use default cross calidation parameters.

```{r}
# Your code here
library(rpart)
fit<-train(cardio~gender+height+weight+ap_hi+ap_lo+cholesterol+gluc+smoke+alco+active+age_years, data=training,method="rpart",control=rpart.control(maxdepth=3))
```

Plot final tree with `rattle` library

```{r}
# Your code here
library(rattle)
fancyRpartPlot(fit$finalModel,main="Cardio feature decision tree plot",sub="Decision tree ver.1")
```

What is the accuracy of prediction on test data?

```{r}
# Your code here
pred<-predict(fit, test)
acc<-sum(pred==test$cardio)/nrow(test)
print(acc)
```

Now set cross validation parameters: `method = "cv"`, `number = 5`. Tree parameters set to default.
```{r}
# Your code here
fitControl<-trainControl(method ="cv",number=5)
fit2<-train(cardio~gender+height+weight+ap_hi+ap_lo+cholesterol+gluc+smoke+alco+active+age_years, data=training,method="rpart",trControl=fitControl)
```

Plot final tree with `rattle` library

```{r}
# Your code here
library(rattle)
fancyRpartPlot(fit2$finalModel,main="Cardio feature decision tree plot",sub="Decision tree ver.2")
```

What is the accuracy of prediction on test data?

```{r}
# Your code here
newPred<-predict(fit2,test)
acc<-sum(newPred==test$cardio)/nrow(test)
print(acc)
```

Does the accuracy became better or not?
**The accuracy and the model outcome itself have not changed, changing the params have not changed the model results**
